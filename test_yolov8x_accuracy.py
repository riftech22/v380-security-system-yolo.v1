#!/usr/bin/env python3
"""Test YOLOv8x model for better accuracy."""

import cv2
import numpy as np
from ultralytics import YOLO
import time

print("=" * 70, flush=True)
print("Test YOLOv8x for Better Accuracy", flush=True)
print("=" * 70, flush=True)
print()

# RTSP URL
RTSP_URL = "rtsp://admin:Kuncong203@10.26.27.196:554/"

print(f"Connecting to RTSP: {RTSP_URL}", flush=True)
print("Testing YOLOv8x vs YOLOv8m...", flush=True)
print()

# Open RTSP
cap = cv2.VideoCapture(RTSP_URL)

if not cap.isOpened():
    print("‚ùå Failed to open RTSP stream!", flush=True)
    exit(1)

print("‚úÖ RTSP opened!", flush=True)

# Load both models
print("\nLoading YOLOv8m model...", flush=True)
model_m = YOLO('yolov8m.pt')

print("Loading YOLOv8x model...", flush=True)
model_x = YOLO('yolov8x.pt')  # Extra large - most accurate

def process_with_model(model, model_name, frame, conf_threshold=0.35):
    """Process frame with specific model."""
    # Resize
    frame_resized = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_LINEAR)
    
    # Brightness adjustment
    brightness = np.mean(frame_resized)
    if brightness > 120:
        frame_resized = cv2.convertScaleAbs(frame_resized, alpha=0.7, beta=-30)
    
    # CLAHE
    lab = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    frame_resized = cv2.merge([l, a, b])
    frame_resized = cv2.cvtColor(frame_resized, cv2.COLOR_LAB2BGR)
    
    # Split frame
    h, w = frame_resized.shape[:2]
    mid_y = h // 2
    top_frame = frame_resized[:mid_y, :]
    bottom_frame = frame_resized[mid_y:, :]
    
    # Detect in top
    results_top = model(top_frame, conf=conf_threshold, classes=[0], verbose=False)
    top_detections = []
    if results_top and results_top[0].boxes:
        for box in results_top[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            conf = float(box.conf[0])
            area = (x2 - x1) * (y2 - y1)
            top_detections.append((x1, y1, x2, y2, conf, area))
    
    # Detect in bottom
    results_bottom = model(bottom_frame, conf=conf_threshold, classes=[0], verbose=False)
    bottom_detections = []
    if results_bottom and results_bottom[0].boxes:
        for box in results_bottom[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            conf = float(box.conf[0])
            area = (x2 - x1) * (y2 - y1)
            bottom_detections.append((x1, y1 + mid_y, x2, y2 + mid_y, conf, area))
    
    all_detections = top_detections + bottom_detections
    return all_detections

# Test 5 frames
frames_processed = 0

while frames_processed < 5:
    ret, frame = cap.read()
    
    if not ret or frame is None:
        print(f"‚ö†Ô∏è  Failed to read frame {frames_processed+1}/5", flush=True)
        time.sleep(0.3)
        continue
    
    print(f"\n{'='*70}", flush=True)
    print(f"Frame {frames_processed+1}/5", flush=True)
    print(f"{'='*70}", flush=True)
    
    # Test YOLOv8m with higher confidence
    print("\nüî∏ YOLOv8m (conf=0.35):", flush=True)
    detections_m = process_with_model(model_m, "YOLOv8m", frame, conf_threshold=0.35)
    print(f"   Persons detected: {len(detections_m)}", flush=True)
    for i, (x1, y1, x2, y2, conf, area) in enumerate(detections_m):
        print(f"      Person {i+1}: conf={conf:.2f}, bbox=({x1},{y1})->({x2},{y2}), area={area}", flush=True)
    
    # Test YOLOv8x with higher confidence
    print("\nüî∏ YOLOv8x (conf=0.35):", flush=True)
    detections_x = process_with_model(model_x, "YOLOv8x", frame, conf_threshold=0.35)
    print(f"   Persons detected: {len(detections_x)}", flush=True)
    for i, (x1, y1, x2, y2, conf, area) in enumerate(detections_x):
        print(f"      Person {i+1}: conf={conf:.2f}, bbox=({x1},{y1})->({x2},{y2}), area={area}", flush=True)
    
    # Comparison
    print(f"\nüìä Comparison:", flush=True)
    print(f"   YOLOv8m: {len(detections_m)} persons", flush=True)
    print(f"   YOLOv8x: {len(detections_x)} persons", flush=True)
    
    if len(detections_x) == 2:  # Expecting 2 persons (user in both cameras)
        print(f"   ‚úÖ YOLOv8x ACCURATE!", flush=True)
    elif len(detections_m) == 2:
        print(f"   ‚úÖ YOLOv8m ACCURATE!", flush=True)
    else:
        print(f"   ‚ö†Ô∏è  Neither model detected 2 persons", flush=True)
    
    frames_processed += 1
    time.sleep(0.5)

cap.release()

print()
print("=" * 70, flush=True)
print("‚úÖ Test Complete!", flush=True)
print("=" * 70, flush=True)
print()

print("üí° RECOMMENDATIONS:", flush=True)
print("   1. YOLOv8x is MORE ACCURATE than YOLOv8m", flush=True)
print("   2. Higher confidence (0.35) reduces false positives", flush=True)
print("   3. YOLOv8x is slower but more precise", flush=True)
print("   4. NO TENSORFLOW NEEDED - Pure PyTorch!", flush=True)
print()
print("üîß NEXT STEPS:", flush=True)
print("   - If YOLOv8x is accurate, use it in production", flush=True)
print("   - Adjust confidence threshold based on results", flush=True)
